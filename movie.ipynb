{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DZfvkqXfyBL"
      },
      "source": [
        "# üé¨ ÏòÅÌôî Ï∂îÏ≤ú ÏãúÏä§ÌÖú - ÏôÑÏ†ÑÌåê\n",
        "\n",
        "## ÌîÑÎ°úÏ†ùÌä∏ Íµ¨Ï°∞\n",
        "\n",
        "```\n",
        "[Part 1] Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
        "    ‚Üì\n",
        "[Part 2] ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\n",
        "         - Œµ-Greedy: epsilon ÌäúÎãù\n",
        "         - DQN: hidden_dim, lstm_hidden, lr Grid Search\n",
        "    ‚Üì\n",
        "[Part 3] ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞Î°ú ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ\n",
        "    ‚Üì\n",
        "[Part 4] 4Í∞ú ÏïåÍ≥†Î¶¨Ï¶ò ÎπÑÍµê ÌèâÍ∞Ä\n",
        "    ‚Üì\n",
        "[Part 5] ÏµúÏ†Å ÏïåÍ≥†Î¶¨Ï¶ò ÏÑ†ÌÉù\n",
        "    ‚Üì\n",
        "[Part 6] Ïú†Ï†ÄÎ≥Ñ ÏòÅÌôî Ï∂îÏ≤ú + TMDB API Ï†ïÎ≥¥ Ï†úÍ≥µ\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yMiEMcRfyBO"
      },
      "source": [
        "## 0. ÌôòÍ≤Ω ÏÑ§Ï†ï"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE9gBZOafyBQ"
      },
      "outputs": [],
      "source": [
        "# GPU ÌôïÏù∏\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSnLYKojfyBR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from collections import defaultdict, deque\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "from itertools import product\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ef7JFJ8fyBR"
      },
      "outputs": [],
      "source": [
        "# TMDB API ÌÇ§ ÏûÖÎ†•\n",
        "# Î∞úÍ∏â: https://www.themoviedb.org/settings/api\n",
        "\n",
        "TMDB_API_KEY = \"YOUR_API_KEY_HERE\"  # <-- Ïó¨Í∏∞Ïóê ÏûÖÎ†•!\n",
        "\n",
        "if TMDB_API_KEY == \"YOUR_API_KEY_HERE\":\n",
        "    print(\"TMDB API ÌÇ§Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî!\")\n",
        "    print(\"   Î∞úÍ∏â: https://www.themoviedb.org/settings/api\")\n",
        "else:\n",
        "    print(\"‚úÖ API ÌÇ§ ÏÑ§Ï†ï ÏôÑÎ£å!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTYu6EHbfyBR"
      },
      "source": [
        "---\n",
        "# Part 1: Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxsNMQlGfyBS"
      },
      "outputs": [],
      "source": [
        "class MovieLensDataLoader:\n",
        "    def __init__(self, save_dir='./data', min_user_ratings=20, min_movie_ratings=5):\n",
        "        self.save_dir = save_dir\n",
        "        self.ratings_path = os.path.join(save_dir, 'ml-latest-small', 'ratings.csv')\n",
        "        self.movies_path = os.path.join(save_dir, 'ml-latest-small', 'movies.csv')\n",
        "        self.min_user_ratings = min_user_ratings\n",
        "        self.min_movie_ratings = min_movie_ratings\n",
        "        self.data = None\n",
        "        self.movies_df = None\n",
        "        self.genre_list = None\n",
        "\n",
        "    def download_data(self):\n",
        "        if not os.path.exists(self.save_dir):\n",
        "            os.makedirs(self.save_dir)\n",
        "        if os.path.exists(self.ratings_path):\n",
        "            print(\"[INFO] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï°¥Ïû¨Ìï©ÎãàÎã§.\")\n",
        "            return\n",
        "        url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "        print(f\"[INFO] Îã§Ïö¥Î°úÎìú Ï§ë...\")\n",
        "        r = requests.get(url)\n",
        "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "        z.extractall(self.save_dir)\n",
        "        print(\"[INFO] ÏôÑÎ£å.\")\n",
        "\n",
        "    def load_and_preprocess(self):\n",
        "        ratings = pd.read_csv(self.ratings_path)\n",
        "        movies = pd.read_csv(self.movies_path)\n",
        "        self.movies_df = movies.copy()\n",
        "\n",
        "        all_genres = set()\n",
        "        for genres in movies['genres']:\n",
        "            for g in genres.split('|'):\n",
        "                if g != '(no genres listed)':\n",
        "                    all_genres.add(g)\n",
        "        self.genre_list = sorted(list(all_genres))\n",
        "\n",
        "        df = pd.merge(ratings, movies, on='movieId', how='left')\n",
        "\n",
        "        movie_counts = df.groupby('movieId')['rating'].count()\n",
        "        valid_movies = movie_counts[movie_counts >= self.min_movie_ratings].index\n",
        "        df = df[df['movieId'].isin(valid_movies)]\n",
        "\n",
        "        user_counts = df.groupby('userId')['rating'].count()\n",
        "        valid_users = user_counts[user_counts >= self.min_user_ratings].index\n",
        "        df = df[df['userId'].isin(valid_users)]\n",
        "\n",
        "        print(f\"[INFO] Îç∞Ïù¥ÌÑ∞: {len(df)} rows, Ïú†Ï†Ä {df['userId'].nunique()}Î™Ö, ÏòÅÌôî {df['movieId'].nunique()}Í∞ú\")\n",
        "\n",
        "        df['liked'] = (df['rating'] >= 4.0).astype(int)\n",
        "\n",
        "        for genre in self.genre_list:\n",
        "            df[f'genre_{genre}'] = df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
        "\n",
        "        self.data = df.sort_values(['userId', 'timestamp']).reset_index(drop=True)\n",
        "        return self.data\n",
        "\n",
        "    def get_movie_info(self, movie_id):\n",
        "        movie = self.movies_df[self.movies_df['movieId'] == movie_id]\n",
        "        if len(movie) == 0:\n",
        "            return None\n",
        "        return {\n",
        "            'movieId': movie_id,\n",
        "            'title': movie['title'].iloc[0],\n",
        "            'genres': movie['genres'].iloc[0]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0JhiF22fyBS"
      },
      "outputs": [],
      "source": [
        "loader = MovieLensDataLoader(min_user_ratings=20, min_movie_ratings=10)\n",
        "loader.download_data()\n",
        "data = loader.load_and_preprocess()\n",
        "print(f\"Ïû•Î•¥ Ïàò: {len(loader.genre_list)}\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPRdKVjffyBS"
      },
      "outputs": [],
      "source": [
        "def temporal_train_test_split(data, test_ratio=0.2):\n",
        "    train_list, test_list = [], []\n",
        "    for user_id, user_df in data.groupby('userId'):\n",
        "        user_df = user_df.sort_values('timestamp')\n",
        "        n = len(user_df)\n",
        "        split_idx = max(1, int(n * (1 - test_ratio)))\n",
        "        train_list.append(user_df.iloc[:split_idx])\n",
        "        test_list.append(user_df.iloc[split_idx:])\n",
        "\n",
        "    train_data = pd.concat(train_list).reset_index(drop=True)\n",
        "    test_data = pd.concat(test_list).reset_index(drop=True)\n",
        "    print(f\"[INFO] Train: {len(train_data)}, Test: {len(test_data)}\")\n",
        "    return train_data, test_data\n",
        "\n",
        "train_data, test_data = temporal_train_test_split(data, test_ratio=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc3MX4cKfyBT"
      },
      "outputs": [],
      "source": [
        "class RecommenderEvaluator:\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "        self.user_ground_truth = {}\n",
        "        for user_id, group in test_data[test_data['liked'] == 1].groupby('userId'):\n",
        "            self.user_ground_truth[user_id] = set(group['movieId'].tolist())\n",
        "\n",
        "    def ndcg_at_k(self, user_id, recs, k):\n",
        "        if user_id not in self.user_ground_truth:\n",
        "            return 0.0\n",
        "        actual = self.user_ground_truth[user_id]\n",
        "        dcg = sum(1.0 / np.log2(i + 2) for i, m in enumerate(recs[:k]) if m in actual)\n",
        "        idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(actual), k)))\n",
        "        return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "    def hit_rate_at_k(self, user_id, recs, k):\n",
        "        if user_id not in self.user_ground_truth:\n",
        "            return 0.0\n",
        "        actual = self.user_ground_truth[user_id]\n",
        "        return 1.0 if len(set(recs[:k]) & actual) > 0 else 0.0\n",
        "\n",
        "    def precision_at_k(self, user_id, recs, k):\n",
        "        if user_id not in self.user_ground_truth:\n",
        "            return 0.0\n",
        "        actual = self.user_ground_truth[user_id]\n",
        "        return sum(1 for m in recs[:k] if m in actual) / k\n",
        "\n",
        "    def recall_at_k(self, user_id, recs, k):\n",
        "        if user_id not in self.user_ground_truth:\n",
        "            return 0.0\n",
        "        actual = self.user_ground_truth[user_id]\n",
        "        if len(actual) == 0:\n",
        "            return 0.0\n",
        "        return len(set(recs[:k]) & actual) / len(actual)\n",
        "\n",
        "    def evaluate_all(self, recommender, user_ids, k=10):\n",
        "        metrics = {'hit': [], 'prec': [], 'recall': [], 'ndcg': []}\n",
        "        for user_id in user_ids:\n",
        "            if user_id not in self.user_ground_truth:\n",
        "                continue\n",
        "            recs = recommender.get_recommendations(user_id, k)\n",
        "            if not recs:\n",
        "                continue\n",
        "            rec_ids = [r['movieId'] for r in recs]\n",
        "            metrics['hit'].append(self.hit_rate_at_k(user_id, rec_ids, k))\n",
        "            metrics['prec'].append(self.precision_at_k(user_id, rec_ids, k))\n",
        "            metrics['recall'].append(self.recall_at_k(user_id, rec_ids, k))\n",
        "            metrics['ndcg'].append(self.ndcg_at_k(user_id, rec_ids, k))\n",
        "\n",
        "        return {\n",
        "            'HitRate@K': np.mean(metrics['hit']) if metrics['hit'] else 0,\n",
        "            'Precision@K': np.mean(metrics['prec']) if metrics['prec'] else 0,\n",
        "            'Recall@K': np.mean(metrics['recall']) if metrics['recall'] else 0,\n",
        "            'NDCG@K': np.mean(metrics['ndcg']) if metrics['ndcg'] else 0,\n",
        "            'n_users': len(metrics['hit'])\n",
        "        }\n",
        "\n",
        "evaluator = RecommenderEvaluator(test_data)\n",
        "print(f\"ÌèâÍ∞Ä Í∞ÄÎä• Ïú†Ï†Ä: {len(evaluator.user_ground_truth)}Î™Ö\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXoauojJfyBT"
      },
      "outputs": [],
      "source": [
        "class MovieEmbedding:\n",
        "    def __init__(self, n_components=20):\n",
        "        self.n_components = n_components\n",
        "        self.svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "        self.movie_vectors = None\n",
        "        self.movie_id_map = None\n",
        "        self.user_vectors = None\n",
        "        self.user_id_map = None\n",
        "\n",
        "    def fit(self, train_data):\n",
        "        matrix = train_data.pivot_table(\n",
        "            index='userId', columns='movieId', values='liked', fill_value=0\n",
        "        )\n",
        "        self.user_id_map = {id: i for i, id in enumerate(matrix.index)}\n",
        "        self.movie_id_map = {id: i for i, id in enumerate(matrix.columns)}\n",
        "        self.movie_ids = list(matrix.columns)\n",
        "\n",
        "        self.user_vectors = self.svd.fit_transform(matrix)\n",
        "        self.movie_vectors = self.svd.components_.T\n",
        "        print(f\"[INFO] SVD ÏôÑÎ£å: {len(self.movie_id_map)}Í∞ú ÏòÅÌôî\")\n",
        "\n",
        "    def get_movie_embedding(self, movie_id):\n",
        "        if movie_id in self.movie_id_map:\n",
        "            return self.movie_vectors[self.movie_id_map[movie_id]]\n",
        "        return np.zeros(self.n_components)\n",
        "\n",
        "    def get_user_embedding(self, user_id):\n",
        "        if user_id in self.user_id_map:\n",
        "            return self.user_vectors[self.user_id_map[user_id]]\n",
        "        return np.zeros(self.n_components)\n",
        "\n",
        "    def predict_score(self, user_id, movie_id):\n",
        "        return np.dot(self.get_user_embedding(user_id), self.get_movie_embedding(movie_id))\n",
        "\n",
        "movie_embedding = MovieEmbedding(n_components=20)\n",
        "movie_embedding.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZsmBXFQfyBU"
      },
      "outputs": [],
      "source": [
        "class SequentialRecommendationEnv:\n",
        "    def __init__(self, train_data, test_data, movie_embedding, seq_length=10, candidate_pool_size=50):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.movie_embedding = movie_embedding\n",
        "        self.seq_length = seq_length\n",
        "        self.candidate_pool_size = candidate_pool_size\n",
        "        self.embed_dim = movie_embedding.n_components\n",
        "\n",
        "        self.all_movie_ids = movie_embedding.movie_ids\n",
        "        self.test_users = test_data['userId'].unique().tolist()\n",
        "\n",
        "        self.user_history = {}\n",
        "        for uid, group in train_data.sort_values('timestamp').groupby('userId'):\n",
        "            self.user_history[uid] = list(zip(group['movieId'].tolist(), group['liked'].tolist()))\n",
        "\n",
        "        self.user_test_likes = {}\n",
        "        for uid, group in test_data.groupby('userId'):\n",
        "            self.user_test_likes[uid] = dict(zip(group['movieId'], group['liked']))\n",
        "\n",
        "        self.current_user = None\n",
        "        self.current_seq = []\n",
        "        self.watched_movies = set()\n",
        "\n",
        "    def reset(self, user_id=None):\n",
        "        if user_id is None:\n",
        "            user_id = random.choice(self.test_users)\n",
        "        self.current_user = user_id\n",
        "        history = self.user_history.get(user_id, [])\n",
        "        self.current_seq = list(history[-self.seq_length:])\n",
        "        self.watched_movies = set(h[0] for h in history)\n",
        "        return self._get_state(), self._get_candidates()\n",
        "\n",
        "    def _get_state(self):\n",
        "        user_embed = self.movie_embedding.get_user_embedding(self.current_user)\n",
        "        seq_embeds, seq_rewards = [], []\n",
        "        for movie_id, liked in self.current_seq:\n",
        "            seq_embeds.append(self.movie_embedding.get_movie_embedding(movie_id))\n",
        "            seq_rewards.append(liked)\n",
        "        while len(seq_embeds) < self.seq_length:\n",
        "            seq_embeds.insert(0, np.zeros(self.embed_dim))\n",
        "            seq_rewards.insert(0, 0)\n",
        "        return {\n",
        "            'user_embed': np.array(user_embed, dtype=np.float32),\n",
        "            'seq_embeds': np.array(seq_embeds, dtype=np.float32),\n",
        "            'seq_rewards': np.array(seq_rewards, dtype=np.float32)\n",
        "        }\n",
        "\n",
        "    def _get_candidates(self):\n",
        "        unwatched = [m for m in self.all_movie_ids if m not in self.watched_movies]\n",
        "        if len(unwatched) <= self.candidate_pool_size:\n",
        "            return unwatched\n",
        "        return random.sample(unwatched, self.candidate_pool_size)\n",
        "\n",
        "    def step(self, action_movie_id):\n",
        "        test_likes = self.user_test_likes.get(self.current_user, {})\n",
        "        if action_movie_id in test_likes:\n",
        "            reward = float(test_likes[action_movie_id])\n",
        "        else:\n",
        "            score = self.movie_embedding.predict_score(self.current_user, action_movie_id)\n",
        "            reward = 1.0 if score > 0.5 else 0.0\n",
        "\n",
        "        self.current_seq.append((action_movie_id, reward))\n",
        "        if len(self.current_seq) > self.seq_length:\n",
        "            self.current_seq.pop(0)\n",
        "        self.watched_movies.add(action_movie_id)\n",
        "\n",
        "        return self._get_state(), reward, len(self._get_candidates()) == 0, self._get_candidates()\n",
        "\n",
        "    def get_movie_embedding(self, movie_id):\n",
        "        return self.movie_embedding.get_movie_embedding(movie_id)\n",
        "\n",
        "env = SequentialRecommendationEnv(train_data, test_data, movie_embedding)\n",
        "print(f\"ÌôòÍ≤Ω: {len(env.test_users)}Î™Ö Ïú†Ï†Ä, {len(env.all_movie_ids)}Í∞ú ÏòÅÌôî\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ0Tv3rhfyBV"
      },
      "source": [
        "## Ï∂îÏ≤ú ÏïåÍ≥†Î¶¨Ï¶ò Íµ¨ÌòÑ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD01P9o3fyBV"
      },
      "outputs": [],
      "source": [
        "class RandomRecommender:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.name = \"Random\"\n",
        "\n",
        "    def get_recommendations(self, user_id, k=10):\n",
        "        state, candidates = self.env.reset(user_id)\n",
        "        selected = random.sample(candidates, min(k, len(candidates)))\n",
        "        return [{'movieId': m, 'score': 0} for m in selected]\n",
        "\n",
        "    def select_action(self, state, candidates):\n",
        "        return random.choice(candidates)\n",
        "\n",
        "class EpsilonGreedyRecommender:\n",
        "    def __init__(self, env, epsilon=0.1):\n",
        "        self.env = env\n",
        "        self.epsilon = epsilon\n",
        "        self.name = f\"Œµ-Greedy(Œµ={epsilon})\"\n",
        "\n",
        "    def get_recommendations(self, user_id, k=10):\n",
        "        state, candidates = self.env.reset(user_id)\n",
        "        scores = [(m, self.env.movie_embedding.predict_score(user_id, m)) for m in candidates]\n",
        "        scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        recs = []\n",
        "        remaining = list(scores)\n",
        "        for _ in range(min(k, len(remaining))):\n",
        "            idx = random.randint(0, len(remaining)-1) if random.random() < self.epsilon else 0\n",
        "            m, score = remaining.pop(idx)\n",
        "            recs.append({'movieId': m, 'score': score})\n",
        "        return recs\n",
        "\n",
        "    def select_action(self, state, candidates):\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(candidates)\n",
        "        scores = [(m, self.env.movie_embedding.predict_score(self.env.current_user, m)) for m in candidates]\n",
        "        return max(scores, key=lambda x: x[1])[0]\n",
        "\n",
        "class ThompsonSamplingRecommender:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.name = \"Thompson Sampling\"\n",
        "        self.alpha = defaultdict(lambda: 1.0)\n",
        "        self.beta = defaultdict(lambda: 1.0)\n",
        "\n",
        "    def update(self, movie_id, reward):\n",
        "        if reward > 0.5:\n",
        "            self.alpha[movie_id] += 1\n",
        "        else:\n",
        "            self.beta[movie_id] += 1\n",
        "\n",
        "    def get_recommendations(self, user_id, k=10):\n",
        "        state, candidates = self.env.reset(user_id)\n",
        "        sampled = []\n",
        "        for m in candidates:\n",
        "            ts = np.random.beta(self.alpha[m], self.beta[m])\n",
        "            svd = self.env.movie_embedding.predict_score(user_id, m)\n",
        "            combined = 0.5 * ts + 0.5 * (svd + 1) / 2\n",
        "            sampled.append((m, combined))\n",
        "        sampled.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [{'movieId': m, 'score': s} for m, s in sampled[:k]]\n",
        "\n",
        "    def select_action(self, state, candidates):\n",
        "        sampled = [(m, np.random.beta(self.alpha[m], self.beta[m])) for m in candidates]\n",
        "        return max(sampled, key=lambda x: x[1])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMRmjVEGfyBW"
      },
      "outputs": [],
      "source": [
        "class SequentialDQNNetwork(nn.Module):\n",
        "    def __init__(self, embed_dim=20, hidden_dim=128, lstm_hidden=64, n_lstm_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed_dim + 1,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=n_lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if n_lstm_layers > 1 else 0\n",
        "        )\n",
        "        input_dim = embed_dim + lstm_hidden + embed_dim\n",
        "        self.q_network = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, user_embed, seq_embeds, seq_rewards, movie_embed):\n",
        "        rewards_expanded = seq_rewards.unsqueeze(-1)\n",
        "        lstm_input = torch.cat([seq_embeds, rewards_expanded], dim=-1)\n",
        "        _, (h_n, _) = self.lstm(lstm_input)\n",
        "        seq_encoding = h_n[-1]\n",
        "        combined = torch.cat([user_embed, seq_encoding, movie_embed], dim=-1)\n",
        "        return self.q_network(combined)\n",
        "\n",
        "class SequentialReplayBuffer:\n",
        "    def __init__(self, capacity=10000):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action_movie_id, movie_embed, reward, next_state, next_candidates, done):\n",
        "        self.buffer.append((state, action_movie_id, movie_embed, reward, next_state, next_candidates, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, action_ids, movie_embeds, rewards, next_states, next_candidates_list, dones = zip(*batch)\n",
        "\n",
        "        return {\n",
        "            'user_embeds': torch.FloatTensor(np.array([s['user_embed'] for s in states])).to(device),\n",
        "            'seq_embeds': torch.FloatTensor(np.array([s['seq_embeds'] for s in states])).to(device),\n",
        "            'seq_rewards': torch.FloatTensor(np.array([s['seq_rewards'] for s in states])).to(device),\n",
        "            'action_ids': action_ids,\n",
        "            'movie_embeds': torch.FloatTensor(np.array(movie_embeds)).to(device),\n",
        "            'rewards': torch.FloatTensor(rewards).to(device),\n",
        "            'dones': torch.FloatTensor(dones).to(device),\n",
        "            'next_user_embeds': torch.FloatTensor(np.array([s['user_embed'] for s in next_states])).to(device),\n",
        "            'next_seq_embeds': torch.FloatTensor(np.array([s['seq_embeds'] for s in next_states])).to(device),\n",
        "            'next_seq_rewards': torch.FloatTensor(np.array([s['seq_rewards'] for s in next_states])).to(device),\n",
        "            'next_candidates_list': next_candidates_list\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "class SequentialDQNRecommender:\n",
        "    def __init__(self, env, embed_dim=20, hidden_dim=128, lstm_hidden=64, lr=0.001, gamma=0.99,\n",
        "                 epsilon_start=1.0, epsilon_end=0.01, epsilon_decay=0.995,\n",
        "                 buffer_size=10000, batch_size=64, target_update=10,\n",
        "                 max_next_candidates=20):\n",
        "\n",
        "        self.env = env\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.target_update = target_update\n",
        "        self.name = \"Sequential-DQN\"\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_hidden = lstm_hidden\n",
        "        self.lr = lr\n",
        "        self.max_next_candidates = max_next_candidates\n",
        "\n",
        "        self.epsilon = epsilon_start\n",
        "        self.epsilon_end = epsilon_end\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "\n",
        "        self.policy_net = SequentialDQNNetwork(embed_dim, hidden_dim, lstm_hidden).to(device)\n",
        "        self.target_net = SequentialDQNNetwork(embed_dim, hidden_dim, lstm_hidden).to(device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.target_net.eval()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n",
        "        self.buffer = SequentialReplayBuffer(buffer_size)\n",
        "\n",
        "        self.train_steps = 0\n",
        "        self.losses = []\n",
        "        self.episode_rewards = []\n",
        "\n",
        "    def select_action(self, state, candidates, training=True):\n",
        "        if training and random.random() < self.epsilon:\n",
        "            return random.choice(candidates)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            user_embed = torch.FloatTensor(state['user_embed']).unsqueeze(0).to(device)\n",
        "            seq_embeds = torch.FloatTensor(state['seq_embeds']).unsqueeze(0).to(device)\n",
        "            seq_rewards = torch.FloatTensor(state['seq_rewards']).unsqueeze(0).to(device)\n",
        "\n",
        "            q_values = []\n",
        "            for movie_id in candidates:\n",
        "                movie_embed = torch.FloatTensor(self.env.get_movie_embedding(movie_id)).unsqueeze(0).to(device)\n",
        "                q = self.policy_net(user_embed, seq_embeds, seq_rewards, movie_embed)\n",
        "                q_values.append((movie_id, q.item()))\n",
        "\n",
        "        return max(q_values, key=lambda x: x[1])[0]\n",
        "\n",
        "    def _compute_max_next_q(self, next_user_embed, next_seq_embeds, next_seq_rewards, next_candidates):\n",
        "        if len(next_candidates) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        if len(next_candidates) > self.max_next_candidates:\n",
        "            sampled_candidates = random.sample(next_candidates, self.max_next_candidates)\n",
        "        else:\n",
        "            sampled_candidates = next_candidates\n",
        "\n",
        "        max_q = float('-inf')\n",
        "        for movie_id in sampled_candidates:\n",
        "            movie_embed = torch.FloatTensor(self.env.get_movie_embedding(movie_id)).unsqueeze(0).to(device)\n",
        "            q = self.target_net(next_user_embed, next_seq_embeds, next_seq_rewards, movie_embed)\n",
        "            max_q = max(max_q, q.item())\n",
        "\n",
        "        return max_q if max_q != float('-inf') else 0.0\n",
        "\n",
        "    def train_step(self):\n",
        "        if len(self.buffer) < self.batch_size:\n",
        "            return None\n",
        "\n",
        "        batch = self.buffer.sample(self.batch_size)\n",
        "\n",
        "        current_q = self.policy_net(\n",
        "            batch['user_embeds'], batch['seq_embeds'], batch['seq_rewards'], batch['movie_embeds']\n",
        "        ).squeeze()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_q_values = []\n",
        "\n",
        "            for i in range(self.batch_size):\n",
        "                reward = batch['rewards'][i].item()\n",
        "                done = batch['dones'][i].item()\n",
        "\n",
        "                if done:\n",
        "                    target_q = reward\n",
        "                else:\n",
        "                    next_user_embed = batch['next_user_embeds'][i].unsqueeze(0)\n",
        "                    next_seq_embeds = batch['next_seq_embeds'][i].unsqueeze(0)\n",
        "                    next_seq_rewards = batch['next_seq_rewards'][i].unsqueeze(0)\n",
        "                    next_candidates = list(batch['next_candidates_list'][i])\n",
        "\n",
        "                    max_next_q = self._compute_max_next_q(\n",
        "                        next_user_embed, next_seq_embeds, next_seq_rewards, next_candidates\n",
        "                    )\n",
        "\n",
        "                    target_q = reward + self.gamma * max_next_q\n",
        "\n",
        "                target_q_values.append(target_q)\n",
        "\n",
        "            target_q = torch.FloatTensor(target_q_values).to(device)\n",
        "\n",
        "        loss = F.smooth_l1_loss(current_q, target_q)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.losses.append(loss.item())\n",
        "        self.train_steps += 1\n",
        "\n",
        "        if self.train_steps % self.target_update == 0:\n",
        "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "        self.epsilon = max(self.epsilon_end, self.epsilon * self.epsilon_decay)\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, n_episodes=500, steps_per_episode=10, verbose=True):\n",
        "        self.episode_rewards = []\n",
        "\n",
        "        for episode in range(n_episodes):\n",
        "            user_id = random.choice(self.env.test_users)\n",
        "            state, candidates = self.env.reset(user_id)\n",
        "            episode_reward = 0\n",
        "\n",
        "            for step in range(steps_per_episode):\n",
        "                if len(candidates) == 0:\n",
        "                    break\n",
        "\n",
        "                action = self.select_action(state, candidates, training=True)\n",
        "                movie_embed = self.env.get_movie_embedding(action)\n",
        "\n",
        "                next_state, reward, done, next_candidates = self.env.step(action)\n",
        "                episode_reward += reward\n",
        "\n",
        "                self.buffer.push(\n",
        "                    state,\n",
        "                    action,\n",
        "                    movie_embed,\n",
        "                    reward,\n",
        "                    next_state,\n",
        "                    next_candidates,\n",
        "                    float(done)\n",
        "                )\n",
        "\n",
        "                self.train_step()\n",
        "\n",
        "                state = next_state\n",
        "                candidates = next_candidates\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            self.episode_rewards.append(episode_reward)\n",
        "\n",
        "            if verbose and (episode + 1) % 100 == 0:\n",
        "                avg_reward = np.mean(self.episode_rewards[-100:])\n",
        "                print(f\"Episode {episode+1}/{n_episodes} | Reward: {avg_reward:.3f} | Œµ: {self.epsilon:.3f}\")\n",
        "\n",
        "        return self.episode_rewards\n",
        "\n",
        "    def get_recommendations(self, user_id, k=10):\n",
        "        state, candidates = self.env.reset(user_id)\n",
        "        recs = []\n",
        "\n",
        "        for _ in range(min(k, len(candidates))):\n",
        "            if not candidates:\n",
        "                break\n",
        "\n",
        "            with torch.no_grad():\n",
        "                user_embed = torch.FloatTensor(state['user_embed']).unsqueeze(0).to(device)\n",
        "                seq_embeds = torch.FloatTensor(state['seq_embeds']).unsqueeze(0).to(device)\n",
        "                seq_rewards = torch.FloatTensor(state['seq_rewards']).unsqueeze(0).to(device)\n",
        "\n",
        "                q_values = []\n",
        "                for movie_id in candidates:\n",
        "                    movie_embed = torch.FloatTensor(self.env.get_movie_embedding(movie_id)).unsqueeze(0).to(device)\n",
        "                    q = self.policy_net(user_embed, seq_embeds, seq_rewards, movie_embed)\n",
        "                    q_values.append((movie_id, q.item()))\n",
        "\n",
        "            q_values.sort(key=lambda x: x[1], reverse=True)\n",
        "            best_movie, best_q = q_values[0]\n",
        "            recs.append({'movieId': best_movie, 'score': best_q})\n",
        "            state, _, _, candidates = self.env.step(best_movie)\n",
        "\n",
        "        return recs\n",
        "\n",
        "    def save_model(self, path='models/dqn_model.pth'):\n",
        "        import os\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        torch.save({\n",
        "            'policy_net': self.policy_net.state_dict(),\n",
        "            'target_net': self.target_net.state_dict(),\n",
        "            'optimizer': self.optimizer.state_dict(),\n",
        "            'epsilon': self.epsilon,\n",
        "            'train_steps': self.train_steps\n",
        "        }, path)\n",
        "        print(f\"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {path}\")\n",
        "\n",
        "    def load_model(self, path='models/dqn_model.pth'):\n",
        "        checkpoint = torch.load(path, map_location=device)\n",
        "        self.policy_net.load_state_dict(checkpoint['policy_net'])\n",
        "        self.target_net.load_state_dict(checkpoint['target_net'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        self.epsilon = checkpoint['epsilon']\n",
        "        self.train_steps = checkpoint.get('train_steps', 0)\n",
        "        print(f\"‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztDsk2uFfyBX"
      },
      "source": [
        "---\n",
        "# Part 2: ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDCR8v_PfyBX"
      },
      "outputs": [],
      "source": [
        "class HyperparameterTuner:\n",
        "    def __init__(self, env, evaluator, test_users):\n",
        "        self.env = env\n",
        "        self.evaluator = evaluator\n",
        "        self.test_users = test_users\n",
        "\n",
        "    def tune_epsilon_greedy(self, epsilon_values=[0.01, 0.05, 0.1, 0.2, 0.3, 0.5]):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Œµ-Greedy ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        results = []\n",
        "        for eps in epsilon_values:\n",
        "            recommender = EpsilonGreedyRecommender(self.env, epsilon=eps)\n",
        "            metrics = self.evaluator.evaluate_all(recommender, self.test_users, k=10)\n",
        "            results.append({'epsilon': eps, **metrics})\n",
        "            print(f\"  Œµ={eps:.2f} -> NDCG@10: {metrics['NDCG@K']:.4f}\")\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def tune_dqn(self,\n",
        "                 hidden_dims=[64, 128, 256],\n",
        "                 lstm_hiddens=[32, 64],\n",
        "                 learning_rates=[0.001, 0.0005],\n",
        "                 n_episodes=300):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Sequential DQN ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        results = []\n",
        "        configs = list(product(hidden_dims, lstm_hiddens, learning_rates))\n",
        "        total = len(configs)\n",
        "\n",
        "        for i, (hidden_dim, lstm_hidden, lr) in enumerate(configs):\n",
        "            print(f\"\\n[{i+1}/{total}] hidden={hidden_dim}, lstm={lstm_hidden}, lr={lr}\")\n",
        "\n",
        "            dqn = SequentialDQNRecommender(\n",
        "                self.env, embed_dim=20, hidden_dim=hidden_dim,\n",
        "                lstm_hidden=lstm_hidden, lr=lr\n",
        "            )\n",
        "            dqn.train(n_episodes=n_episodes, verbose=False)\n",
        "\n",
        "            metrics = self.evaluator.evaluate_all(dqn, self.test_users[:50], k=10)\n",
        "\n",
        "            results.append({\n",
        "                'hidden_dim': hidden_dim,\n",
        "                'lstm_hidden': lstm_hidden,\n",
        "                'lr': lr,\n",
        "                'final_reward': np.mean(dqn.episode_rewards[-50:]) if dqn.episode_rewards else 0,\n",
        "                **metrics\n",
        "            })\n",
        "            print(f\"  -> NDCG@10: {metrics['NDCG@K']:.4f}\")\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def plot_tuning_results(self, epsilon_results, dqn_results):\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "        ax1 = axes[0, 0]\n",
        "        ax1.plot(epsilon_results['epsilon'], epsilon_results['NDCG@K'], 'bo-', linewidth=2, markersize=8)\n",
        "        ax1.set_xlabel('Epsilon (Œµ)')\n",
        "        ax1.set_ylabel('NDCG@10')\n",
        "        ax1.set_title('Œµ-Greedy: Epsilon Tuning')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        best_idx = epsilon_results['NDCG@K'].idxmax()\n",
        "        best_eps = epsilon_results.loc[best_idx, 'epsilon']\n",
        "        ax1.axvline(x=best_eps, color='r', linestyle='--', label=f'Best Œµ={best_eps}')\n",
        "        ax1.legend()\n",
        "\n",
        "        ax2 = axes[0, 1]\n",
        "        for metric in ['HitRate@K', 'Precision@K', 'Recall@K', 'NDCG@K']:\n",
        "            ax2.plot(epsilon_results['epsilon'], epsilon_results[metric], 'o-', label=metric)\n",
        "        ax2.set_xlabel('Epsilon (Œµ)')\n",
        "        ax2.set_ylabel('Score')\n",
        "        ax2.set_title('Œµ-Greedy: All Metrics')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        ax3 = axes[1, 0]\n",
        "        for lr in dqn_results['lr'].unique():\n",
        "            subset = dqn_results[dqn_results['lr'] == lr]\n",
        "            lstm_val = subset['lstm_hidden'].iloc[0]\n",
        "            subset_lstm = subset[subset['lstm_hidden'] == lstm_val]\n",
        "            ax3.plot(subset_lstm['hidden_dim'], subset_lstm['NDCG@K'], 'o-', label=f'lr={lr}')\n",
        "        ax3.set_xlabel('Hidden Dimension')\n",
        "        ax3.set_ylabel('NDCG@10')\n",
        "        ax3.set_title('DQN: Hidden Dim Tuning')\n",
        "        ax3.legend()\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "\n",
        "        ax4 = axes[1, 1]\n",
        "        pivot = dqn_results.pivot_table(\n",
        "            values='NDCG@K', index='hidden_dim', columns='lstm_hidden', aggfunc='mean'\n",
        "        )\n",
        "        sns.heatmap(pivot, annot=True, fmt='.4f', cmap='YlOrRd', ax=ax4)\n",
        "        ax4.set_title('DQN: NDCG@10 Heatmap')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('hyperparameter_tuning.png', dpi=150)\n",
        "        plt.show()\n",
        "        return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3epuTnwGfyBY"
      },
      "outputs": [],
      "source": [
        "test_users = list(evaluator.user_ground_truth.keys())\n",
        "eval_users = random.sample(test_users, min(100, len(test_users)))\n",
        "print(f\"ÌèâÍ∞Ä Ïú†Ï†Ä: {len(eval_users)}Î™Ö\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCdVWWmzfyBZ"
      },
      "outputs": [],
      "source": [
        "tuner = HyperparameterTuner(env, evaluator, eval_users)\n",
        "\n",
        "epsilon_results = tuner.tune_epsilon_greedy(\n",
        "    epsilon_values=[0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5]\n",
        ")\n",
        "print(\"\\n[Epsilon ÌäúÎãù Í≤∞Í≥º]\")\n",
        "display(epsilon_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz10wtDbfyBZ"
      },
      "outputs": [],
      "source": [
        "dqn_results = tuner.tune_dqn(\n",
        "    hidden_dims=[32, 64],\n",
        "    lstm_hiddens=[16, 32],\n",
        "    learning_rates=[0.001, 0.0005],\n",
        "    n_episodes=100\n",
        ")\n",
        "print(\"\\n[DQN ÌäúÎãù Í≤∞Í≥º]\")\n",
        "display(dqn_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJS9V_pAfyBZ"
      },
      "outputs": [],
      "source": [
        "tuner.plot_tuning_results(epsilon_results, dqn_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1mcxWTFfyBa"
      },
      "source": [
        "---\n",
        "# Part 3: ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞Î°ú ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXkI_DIMfyBa"
      },
      "outputs": [],
      "source": [
        "best_epsilon = epsilon_results.loc[epsilon_results['NDCG@K'].idxmax(), 'epsilon']\n",
        "best_dqn_config = dqn_results.loc[dqn_results['NDCG@K'].idxmax()]\n",
        "\n",
        "print(\"[ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞]\")\n",
        "print(f\"  Œµ-Greedy: epsilon = {best_epsilon}\")\n",
        "print(f\"  DQN: hidden={int(best_dqn_config['hidden_dim'])}, \"\n",
        "      f\"lstm={int(best_dqn_config['lstm_hidden'])}, \"\n",
        "      f\"lr={best_dqn_config['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7IhvsTZfyBa"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ]\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "final_recommenders = {}\n",
        "\n",
        "final_recommenders['Random'] = RandomRecommender(env)\n",
        "print(\"  ‚úì Random\")\n",
        "\n",
        "final_recommenders[f'Œµ-Greedy(Œµ={best_epsilon})'] = EpsilonGreedyRecommender(env, best_epsilon)\n",
        "print(f\"  ‚úì Œµ-Greedy (Œµ={best_epsilon})\")\n",
        "\n",
        "final_recommenders['Thompson'] = ThompsonSamplingRecommender(env)\n",
        "print(\"  ‚úì Thompson Sampling\")\n",
        "\n",
        "print(\"\\n  Sequential DQN ÌïôÏäµ Ï§ë...\")\n",
        "final_dqn = SequentialDQNRecommender(\n",
        "    env, embed_dim=20,\n",
        "    hidden_dim=int(best_dqn_config['hidden_dim']),\n",
        "    lstm_hidden=int(best_dqn_config['lstm_hidden']),\n",
        "    lr=best_dqn_config['lr']\n",
        ")\n",
        "\n",
        "N_EPISODES = 1000 if torch.cuda.is_available() else 500\n",
        "final_dqn.train(n_episodes=N_EPISODES, steps_per_episode=10)\n",
        "\n",
        "final_dqn.save_model('models/dqn_model.pth');\n",
        "final_recommenders['Sequential-DQN'] = final_dqn\n",
        "\n",
        "print(f\"\\nÏ¥ù {len(final_recommenders)}Í∞ú Î™®Îç∏ Ï§ÄÎπÑ ÏôÑÎ£å\")\n",
        "\n",
        "final_dqn.save_model('models/dqn_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHz-EprtfyBb"
      },
      "source": [
        "---\n",
        "# Part 4: ÏïåÍ≥†Î¶¨Ï¶ò ÎπÑÍµê ÌèâÍ∞Ä\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emp1pGvnfyBb"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[ÏµúÏ¢Ö ÌèâÍ∞Ä]\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "final_results = []\n",
        "K = 10\n",
        "\n",
        "for name, recommender in final_recommenders.items():\n",
        "    print(f\"  ÌèâÍ∞Ä: {name}...\")\n",
        "    metrics = evaluator.evaluate_all(recommender, eval_users, k=K)\n",
        "    metrics['Algorithm'] = name\n",
        "    final_results.append(metrics)\n",
        "\n",
        "final_df = pd.DataFrame(final_results)\n",
        "final_df = final_df[['Algorithm', 'HitRate@K', 'Precision@K', 'Recall@K', 'NDCG@K', 'n_users']]\n",
        "\n",
        "print(\"\\n[Í≤∞Í≥º]\")\n",
        "display(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN9HARXufyBb"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[Ïò®ÎùºÏù∏ ÏãúÎÆ¨Î†àÏù¥ÏÖò]\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "N_SIM_STEPS = 500\n",
        "cumulative_rewards = {name: [] for name in final_recommenders.keys()}\n",
        "\n",
        "for name, recommender in final_recommenders.items():\n",
        "    total_reward = 0\n",
        "    rewards_history = []\n",
        "\n",
        "    if isinstance(recommender, ThompsonSamplingRecommender):\n",
        "        recommender.alpha = defaultdict(lambda: 1.0)\n",
        "        recommender.beta = defaultdict(lambda: 1.0)\n",
        "\n",
        "    for step in range(N_SIM_STEPS):\n",
        "        user_id = random.choice(env.test_users)\n",
        "        state, candidates = env.reset(user_id)\n",
        "        if not candidates:\n",
        "            continue\n",
        "        action = recommender.select_action(state, candidates)\n",
        "        _, reward, _, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        if isinstance(recommender, ThompsonSamplingRecommender):\n",
        "            recommender.update(action, reward)\n",
        "        rewards_history.append(total_reward)\n",
        "\n",
        "    cumulative_rewards[name] = rewards_history\n",
        "    print(f\"  {name}: Ï¥ù Î¶¨ÏõåÎìú = {total_reward:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAt2Nc7ffyBc"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "ax1 = fig.add_subplot(2, 3, 1)\n",
        "metrics_cols = ['HitRate@K', 'Precision@K', 'Recall@K', 'NDCG@K']\n",
        "x = np.arange(len(final_df))\n",
        "width = 0.2\n",
        "for i, metric in enumerate(metrics_cols):\n",
        "    ax1.bar(x + i*width, final_df[metric], width, label=metric)\n",
        "ax1.set_xlabel('Algorithm')\n",
        "ax1.set_ylabel('Score')\n",
        "ax1.set_title('Offline Evaluation (K=10)')\n",
        "ax1.set_xticks(x + width * 1.5)\n",
        "ax1.set_xticklabels(final_df['Algorithm'], rotation=45, ha='right')\n",
        "ax1.legend(loc='upper right')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "ax2 = fig.add_subplot(2, 3, 2)\n",
        "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(final_df)))\n",
        "bars = ax2.bar(final_df['Algorithm'], final_df['NDCG@K'], color=colors)\n",
        "ax2.set_ylabel('NDCG@10')\n",
        "ax2.set_title('NDCG@10 Comparison')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "for bar, val in zip(bars, final_df['NDCG@K']):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002, f'{val:.4f}', ha='center', fontsize=9)\n",
        "\n",
        "ax3 = fig.add_subplot(2, 3, 3)\n",
        "for name, rewards in cumulative_rewards.items():\n",
        "    ax3.plot(rewards, label=name, linewidth=2)\n",
        "ax3.set_xlabel('Step')\n",
        "ax3.set_ylabel('Cumulative Reward')\n",
        "ax3.set_title('Online Simulation')\n",
        "ax3.legend(loc='upper left')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "ax4 = fig.add_subplot(2, 3, 4)\n",
        "window = 50\n",
        "if final_dqn.episode_rewards:\n",
        "    smoothed = np.convolve(final_dqn.episode_rewards, np.ones(window)/window, mode='valid')\n",
        "    ax4.plot(smoothed, linewidth=2)\n",
        "ax4.set_xlabel('Episode')\n",
        "ax4.set_ylabel('Avg Reward')\n",
        "ax4.set_title('Sequential DQN Training')\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "ax5 = fig.add_subplot(2, 3, 5)\n",
        "if final_dqn.losses:\n",
        "    smoothed_loss = np.convolve(final_dqn.losses, np.ones(window)/window, mode='valid')\n",
        "    ax5.plot(smoothed_loss, linewidth=2, color='orange')\n",
        "ax5.set_xlabel('Training Step')\n",
        "ax5.set_ylabel('Loss')\n",
        "ax5.set_title('DQN Training Loss')\n",
        "ax5.grid(alpha=0.3)\n",
        "\n",
        "ax6 = fig.add_subplot(2, 3, 6)\n",
        "random_ndcg = final_df[final_df['Algorithm'] == 'Random']['NDCG@K'].values[0]\n",
        "improvements, names = [], []\n",
        "for _, row in final_df.iterrows():\n",
        "    if row['Algorithm'] != 'Random':\n",
        "        imp = (row['NDCG@K'] - random_ndcg) / random_ndcg * 100 if random_ndcg > 0 else 0\n",
        "        improvements.append(imp)\n",
        "        names.append(row['Algorithm'])\n",
        "colors = ['green' if x > 0 else 'red' for x in improvements]\n",
        "bars = ax6.barh(names, improvements, color=colors, alpha=0.7)\n",
        "ax6.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax6.set_xlabel('Improvement over Random (%)')\n",
        "ax6.set_title('NDCG@10 Improvement vs Random')\n",
        "for bar, val in zip(bars, improvements):\n",
        "    ax6.text(val + 1, bar.get_y() + bar.get_height()/2, f'+{val:.1f}%', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('final_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxqvnd2JfyBc"
      },
      "source": [
        "---\n",
        "# Part 5: ÏµúÏ†Å ÏïåÍ≥†Î¶¨Ï¶ò ÏÑ†ÌÉù\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDxr46g7fyBd"
      },
      "outputs": [],
      "source": [
        "best_idx = final_df['NDCG@K'].idxmax()\n",
        "best_algo_name = final_df.loc[best_idx, 'Algorithm']\n",
        "best_ndcg = final_df.loc[best_idx, 'NDCG@K']\n",
        "\n",
        "best_recommender = final_recommenders[best_algo_name]\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"üèÜ ÏµúÏ†Å ÏïåÍ≥†Î¶¨Ï¶ò: {best_algo_name}\")\n",
        "print(f\"   NDCG@10: {best_ndcg:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT-PAczNfyBd"
      },
      "source": [
        "---\n",
        "# Part 6: ÏµúÏ¢Ö Ï∂îÏ≤ú ÏãúÏä§ÌÖú (TMDB API)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiNuhyF2fyBd"
      },
      "outputs": [],
      "source": [
        "class TMDBMovieInfo:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://api.themoviedb.org/3\"\n",
        "        self.image_base_url = \"https://image.tmdb.org/t/p/w500\"\n",
        "        self.cache = {}\n",
        "\n",
        "    def search_movie(self, title, year=None):\n",
        "        cache_key = f\"{title}_{year}\"\n",
        "        if cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        url = f\"{self.base_url}/search/movie\"\n",
        "        params = {'api_key': self.api_key, 'query': title, 'language': 'ko-KR'}\n",
        "        if year:\n",
        "            params['year'] = year\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, params=params, timeout=10)\n",
        "            data = response.json()\n",
        "            if data.get('results') and len(data['results']) > 0:\n",
        "                movie = data['results'][0]\n",
        "                result = self._parse_movie_data(movie)\n",
        "                self.cache[cache_key] = result\n",
        "                return result\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"[TMDB Error] {e}\")\n",
        "            return None\n",
        "\n",
        "    def _parse_movie_data(self, movie):\n",
        "        poster_path = movie.get('poster_path')\n",
        "        poster_url = f\"{self.image_base_url}{poster_path}\" if poster_path else None\n",
        "        return {\n",
        "            'tmdb_id': movie.get('id'),\n",
        "            'title': movie.get('title'),\n",
        "            'original_title': movie.get('original_title'),\n",
        "            'overview': movie.get('overview', 'Ï§ÑÍ±∞Î¶¨ Ï†ïÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§.'),\n",
        "            'release_date': movie.get('release_date', ''),\n",
        "            'vote_average': movie.get('vote_average', 0),\n",
        "            'vote_count': movie.get('vote_count', 0),\n",
        "            'poster_url': poster_url\n",
        "        }\n",
        "\n",
        "    def get_movie_details(self, tmdb_id):\n",
        "        url = f\"{self.base_url}/movie/{tmdb_id}\"\n",
        "        params = {'api_key': self.api_key, 'language': 'ko-KR'}\n",
        "        try:\n",
        "            response = requests.get(url, params=params, timeout=10)\n",
        "            data = response.json()\n",
        "            genres = [g['name'] for g in data.get('genres', [])]\n",
        "            return {'genres': genres, 'runtime': data.get('runtime', 0), 'tagline': data.get('tagline', '')}\n",
        "        except:\n",
        "            return {'genres': [], 'runtime': 0, 'tagline': ''}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j15GW4zqfyBe"
      },
      "outputs": [],
      "source": [
        "class FinalRecommendationSystem:\n",
        "    def __init__(self, recommender, loader, tmdb_api_key):\n",
        "        self.recommender = recommender\n",
        "        self.loader = loader\n",
        "        self.tmdb = TMDBMovieInfo(tmdb_api_key) if tmdb_api_key != \"YOUR_API_KEY_HERE\" else None\n",
        "\n",
        "    def _parse_movielens_title(self, title):\n",
        "        try:\n",
        "            if '(' in title and ')' in title:\n",
        "                year_str = title[title.rfind('(')+1:title.rfind(')')]\n",
        "                clean_title = title[:title.rfind('(')].strip()\n",
        "                return clean_title, int(year_str)\n",
        "        except:\n",
        "            pass\n",
        "        return title, None\n",
        "\n",
        "    def recommend_for_user(self, user_id, n_recommendations=5):\n",
        "        recs = self.recommender.get_recommendations(user_id, k=n_recommendations)\n",
        "        if not recs:\n",
        "            return []\n",
        "\n",
        "        recommendations = []\n",
        "        for i, rec in enumerate(recs):\n",
        "            movie_id = rec['movieId']\n",
        "            score = rec['score']\n",
        "            ml_info = self.loader.get_movie_info(movie_id)\n",
        "            if ml_info is None:\n",
        "                continue\n",
        "\n",
        "            movie_data = {\n",
        "                'rank': i + 1,\n",
        "                'movieId': movie_id,\n",
        "                'ml_title': ml_info['title'],\n",
        "                'ml_genres': ml_info['genres'],\n",
        "                'score': score\n",
        "            }\n",
        "\n",
        "            if self.tmdb:\n",
        "                clean_title, year = self._parse_movielens_title(ml_info['title'])\n",
        "                tmdb_info = self.tmdb.search_movie(clean_title, year)\n",
        "                if tmdb_info:\n",
        "                    movie_data['tmdb'] = tmdb_info\n",
        "                    details = self.tmdb.get_movie_details(tmdb_info['tmdb_id'])\n",
        "                    movie_data['tmdb_details'] = details\n",
        "\n",
        "            recommendations.append(movie_data)\n",
        "        return recommendations\n",
        "\n",
        "    def display_recommendations(self, user_id, n_recommendations=5):\n",
        "        recommendations = self.recommend_for_user(user_id, n_recommendations)\n",
        "        if not recommendations:\n",
        "            print(f\"Ïú†Ï†Ä {user_id}ÏóêÍ≤å Ï∂îÏ≤úÌï† ÏòÅÌôîÍ∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
        "            return\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style=\"font-family: 'Segoe UI', Arial, sans-serif; max-width: 900px; margin: 0 auto;\">\n",
        "            <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                        color: white; padding: 20px; border-radius: 15px 15px 0 0; text-align: center;\">\n",
        "                <h1 style=\"margin: 0;\">üé¨ Ïú†Ï†Ä #{user_id}ÎãòÏùÑ ÏúÑÌïú Ï∂îÏ≤ú ÏòÅÌôî</h1>\n",
        "                <p style=\"margin: 10px 0 0 0; opacity: 0.9;\">Ï∂îÏ≤ú ÏïåÍ≥†Î¶¨Ï¶ò: {self.recommender.name}</p>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "\n",
        "        for movie in recommendations:\n",
        "            rank = movie['rank']\n",
        "            title = movie['ml_title']\n",
        "            genres = movie['ml_genres']\n",
        "\n",
        "            poster_html = \"\"\n",
        "            overview = \"ÏòÅÌôî Ï†ïÎ≥¥Î•º Î∂àÎü¨Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§.\"\n",
        "            tmdb_rating = \"\"\n",
        "            tmdb_genres = genres.replace('|', ', ')\n",
        "\n",
        "            if 'tmdb' in movie:\n",
        "                tmdb = movie['tmdb']\n",
        "                if tmdb.get('poster_url'):\n",
        "                    poster_html = f'<img src=\"{tmdb[\"poster_url\"]}\" style=\"width: 150px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\" alt=\"{title}\">'\n",
        "                overview = tmdb.get('overview', 'Ï§ÑÍ±∞Î¶¨ Ï†ïÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§.')\n",
        "                if len(overview) > 300:\n",
        "                    overview = overview[:300] + '...'\n",
        "                if tmdb.get('vote_average'):\n",
        "                    rating = tmdb['vote_average']\n",
        "                    stars = '‚òÖ' * int(rating/2) + '‚òÜ' * (5 - int(rating/2))\n",
        "                    tmdb_rating = f\"<span style='color: #f39c12;'>{stars}</span> ({rating}/10)\"\n",
        "                if 'tmdb_details' in movie and movie['tmdb_details'].get('genres'):\n",
        "                    tmdb_genres = ', '.join(movie['tmdb_details']['genres'])\n",
        "\n",
        "            medal_colors = {1: '#FFD700', 2: '#C0C0C0', 3: '#CD7F32'}\n",
        "            medal_color = medal_colors.get(rank, '#667eea')\n",
        "\n",
        "            html += f\"\"\"\n",
        "            <div style=\"display: flex; background: white; margin: 15px; padding: 20px;\n",
        "                        border-radius: 15px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);\">\n",
        "                <div style=\"text-align: center; margin-right: 20px;\">\n",
        "                    <div style=\"background: {medal_color}; color: white; width: 40px; height: 40px;\n",
        "                                border-radius: 50%; display: flex; align-items: center; justify-content: center;\n",
        "                                font-weight: bold; font-size: 18px; margin: 0 auto 10px auto;\">{rank}</div>\n",
        "                    {poster_html if poster_html else '<div style=\"width:150px;height:225px;background:#eee;border-radius:10px;display:flex;align-items:center;justify-content:center;color:#999;\">No Poster</div>'}\n",
        "                </div>\n",
        "                <div style=\"flex: 1;\">\n",
        "                    <h2 style=\"margin: 0 0 10px 0; color: #333;\">{title}</h2>\n",
        "                    <div style=\"margin-bottom: 10px;\">\n",
        "                        <span style=\"background: #667eea; color: white; padding: 3px 10px;\n",
        "                                     border-radius: 15px; font-size: 12px;\">{tmdb_genres}</span>\n",
        "                    </div>\n",
        "                    <p style=\"color: #666; line-height: 1.6; margin: 10px 0;\">{overview}</p>\n",
        "                    <div style=\"display: flex; gap: 20px; margin-top: 15px; color: #888; font-size: 14px;\">\n",
        "                        <span>üéØ Ï∂îÏ≤ú Ï†êÏàò: <strong>{movie['score']:.2f}</strong></span>\n",
        "                        {f'<span>‚≠ê TMDB ÌèâÏ†ê: {tmdb_rating}</span>' if tmdb_rating else ''}\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"</div>\"\n",
        "        display(HTML(html))\n",
        "        return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGaa7I3ufyBe"
      },
      "outputs": [],
      "source": [
        "final_system = FinalRecommendationSystem(\n",
        "    recommender=best_recommender,\n",
        "    loader=loader,\n",
        "    tmdb_api_key=TMDB_API_KEY\n",
        ")\n",
        "\n",
        "if TMDB_API_KEY == \"YOUR_API_KEY_HERE\":\n",
        "    print(\"‚ö†Ô∏è TMDB API ÌÇ§Î•º ÏûÖÎ†•ÌïòÎ©¥ Ìè¨Ïä§ÌÑ∞ÏôÄ Ï§ÑÍ±∞Î¶¨Í∞Ä ÌëúÏãúÎê©ÎãàÎã§!\")\n",
        "else:\n",
        "    print(\"‚úÖ TMDB API Ïó∞Îèô ÏôÑÎ£å!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RxScrUvfyBf"
      },
      "source": [
        "## üé¨ ÏòÅÌôî Ï∂îÏ≤ú Ïã§Ìñâ!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNm7e2mVfyBf"
      },
      "outputs": [],
      "source": [
        "sample_user = random.choice(eval_users)\n",
        "print(f\"Ïú†Ï†Ä #{sample_user}ÏóêÍ≤å Ï∂îÏ≤ú Ï§ë...\\n\")\n",
        "final_system.display_recommendations(sample_user, n_recommendations=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg-gwGRKfyBf"
      },
      "outputs": [],
      "source": [
        "another_user = random.choice(eval_users)\n",
        "print(f\"Ïú†Ï†Ä #{another_user}ÏóêÍ≤å Ï∂îÏ≤ú Ï§ë...\\n\")\n",
        "final_system.display_recommendations(another_user, n_recommendations=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQjV79JvfyBg"
      },
      "outputs": [],
      "source": [
        "sample_users = random.sample(eval_users, 3)\n",
        "for user_id in sample_users:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    final_system.display_recommendations(user_id, n_recommendations=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXwGAPn2fyBg"
      },
      "source": [
        "---\n",
        "# üìä ÏµúÏ¢Ö ÏöîÏïΩ\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEPQBWzVfyBq"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üìä ÌîÑÎ°úÏ†ùÌä∏ Í≤∞Í≥º ÏöîÏïΩ\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n[1] ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\")\n",
        "print(\"-\"*50)\n",
        "print(f\"  ÏµúÏ†Å Epsilon: {best_epsilon}\")\n",
        "print(f\"  ÏµúÏ†Å DQN: hidden={int(best_dqn_config['hidden_dim'])}, \"\n",
        "      f\"lstm={int(best_dqn_config['lstm_hidden'])}, lr={best_dqn_config['lr']}\")\n",
        "\n",
        "print(\"\\n[2] ÏïåÍ≥†Î¶¨Ï¶ò ÎπÑÍµê Í≤∞Í≥º\")\n",
        "print(\"-\"*50)\n",
        "print(final_df.to_string(index=False))\n",
        "\n",
        "print(f\"\\n[3] ÏµúÏ†Å ÏïåÍ≥†Î¶¨Ï¶ò\")\n",
        "print(\"-\"*50)\n",
        "print(f\"  üèÜ {best_algo_name}\")\n",
        "print(f\"  NDCG@10: {best_ndcg:.4f}\")\n",
        "\n",
        "random_ndcg = final_df[final_df['Algorithm'] == 'Random']['NDCG@K'].values[0]\n",
        "improvement = (best_ndcg - random_ndcg) / random_ndcg * 100 if random_ndcg > 0 else 0\n",
        "print(f\"  Random ÎåÄÎπÑ: +{improvement:.1f}%\")\n",
        "\n",
        "print(f\"\\n[4] ÏµúÏ¢Ö ÏãúÏä§ÌÖú\")\n",
        "print(\"-\"*50)\n",
        "print(f\"  Ï∂îÏ≤ú ÏïåÍ≥†Î¶¨Ï¶ò: {best_algo_name}\")\n",
        "print(f\"  ÏòÅÌôî Ï†ïÎ≥¥: {'TMDB API (Ìè¨Ïä§ÌÑ∞ + Ï§ÑÍ±∞Î¶¨)' if TMDB_API_KEY != 'YOUR_API_KEY_HERE' else 'MovieLens Í∏∞Î≥∏'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ ÌîÑÎ°úÏ†ùÌä∏ ÏôÑÎ£å!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0O2-ymbfyBq"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv('final_results.csv', index=False)\n",
        "epsilon_results.to_csv('epsilon_tuning.csv', index=False)\n",
        "dqn_results.to_csv('dqn_tuning.csv', index=False)\n",
        "print(\"Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}